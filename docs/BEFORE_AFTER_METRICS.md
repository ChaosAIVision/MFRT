# HuggingFace API - Before/After Metrics Example

## New Output Structure v·ªõi Before/After Comparison

```json
{
  "success": true,
  "initial_prompt": "B·∫°n l√† chatbot b√°n s·ªØa Abbott. Tr·∫£ l·ªùi: {customer_question}",
  "optimized_prompt": "B·∫°n l√† chatbot b√°n s·ªØa Abbott chuy√™n nghi·ªáp...",

  "metrics_before": {
    "quality": {
      "distribution": {
        "poor": 5,
        "good": 5
      }
    }
  },

  "metrics_after": {
    "quality": {
      "distribution": {
        "poor": 1,
        "good": 9
      }
    }
  },

  "improvement": {
    "quality": {
      "before_distribution": {"poor": 5, "good": 5},
      "after_distribution": {"poor": 1, "good": 9},
      "positive_count_before": 5,
      "positive_count_after": 9,
      "improvement": 4,
      "before_positive_pct": 50.0,
      "after_positive_pct": 90.0
    }
  }
}
```

---

## Gi·∫£i th√≠ch chi ti·∫øt

### 1. **`metrics_before`** - Baseline (TR∆Ø·ªöC optimize)

ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng outputs ƒë∆∞·ª£c t·∫°o t·ª´ **INITIAL PROMPT**:

```json
"metrics_before": {
  "quality": {
    "distribution": {
      "poor": 5,   // 5/10 c√¢u tr·∫£ l·ªùi K√âM
      "good": 5    // 5/10 c√¢u tr·∫£ l·ªùi T·ªêT
    }
  }
}
```

**Timeline:**
```
Dataset c√≥ 10 samples
  ‚Üì
Chatbot d√πng INITIAL PROMPT tr·∫£ l·ªùi 10 c√¢u
  ‚Üì
Evaluator ƒë√°nh gi√° 10 outputs
  ‚Üì
K·∫øt qu·∫£: 50% good, 50% poor ‚Üê metrics_before
```

---

### 2. **`metrics_after`** - Results (SAU optimize)

ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng outputs ƒë∆∞·ª£c t·∫°o t·ª´ **OPTIMIZED PROMPT**:

```json
"metrics_after": {
  "quality": {
    "distribution": {
      "poor": 1,   // Ch·ªâ c√≤n 1/10 c√¢u K√âM
      "good": 9    // TƒÉng l√™n 9/10 c√¢u T·ªêT
    }
  }
}
```

**Timeline:**
```
Optimizer t·∫°o OPTIMIZED PROMPT
  ‚Üì
Chatbot d√πng OPTIMIZED PROMPT tr·∫£ l·ªùi L·∫†I 10 c√¢u
  ‚Üì
Evaluator ƒë√°nh gi√° l·∫°i 10 outputs m·ªõi
  ‚Üì
K·∫øt qu·∫£: 90% good, 10% poor ‚Üê metrics_after
```

---

### 3. **`improvement`** - So s√°nh Before vs After

T·ªïng h·ª£p s·ª± c·∫£i thi·ªán:

```json
"improvement": {
  "quality": {
    "before_distribution": {"poor": 5, "good": 5},
    "after_distribution": {"poor": 1, "good": 9},

    "positive_count_before": 5,     // 5 c√¢u t·ªët TR∆Ø·ªöC
    "positive_count_after": 9,      // 9 c√¢u t·ªët SAU
    "improvement": 4,               // C·∫£i thi·ªán +4 c√¢u

    "before_positive_pct": 50.0,    // 50% T·ªêT tr∆∞·ªõc
    "after_positive_pct": 90.0      // 90% T·ªêT sau
  }
}
```

**√ù nghƒ©a:**
- **improvement: +4** = TƒÉng 4 c√¢u tr·∫£ l·ªùi t·ªët (t·ª´ 5 ‚Üí 9)
- **before_positive_pct: 50%** = Ch·∫•t l∆∞·ª£ng ban ƒë·∫ßu (baseline)
- **after_positive_pct: 90%** = Ch·∫•t l∆∞·ª£ng sau optimize
- **T·ªïng c·∫£i thi·ªán: +40%** (t·ª´ 50% ‚Üí 90%)

---

## Visualization

### Before Optimization:
```
Initial Prompt: "B·∫°n l√† chatbot b√°n s·ªØa Abbott. Tr·∫£ l·ªùi: {customer_question}"

Quality Distribution:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ùå Poor:  5 (50%)         ‚îÇ
‚îÇ  ‚úÖ Good:  5 (50%)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### After Optimization:
```
Optimized Prompt: "B·∫°n l√† chatbot b√°n s·ªØa Abbott chuy√™n nghi·ªáp, th√¢n thi·ªán..."
(v·ªõi h∆∞·ªõng d·∫´n chi ti·∫øt + v√≠ d·ª• c·ª• th·ªÉ)

Quality Distribution:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ùå Poor:  1 (10%)         ‚îÇ
‚îÇ  ‚úÖ Good:  9 (90%)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìà IMPROVEMENT: +40% (50% ‚Üí 90%)
```

---

## V√≠ d·ª• v·ªõi Numeric Metrics

N·∫øu feedback l√† ƒëi·ªÉm s·ªë (0-1):

### Before:
```json
"metrics_before": {
  "accuracy_score": {
    "mean": 0.65,
    "std": 0.25,
    "min": 0.2,
    "max": 1.0
  }
}
```

### After:
```json
"metrics_after": {
  "accuracy_score": {
    "mean": 0.88,
    "std": 0.12,
    "min": 0.6,
    "max": 1.0
  }
}
```

### Improvement:
```json
"improvement": {
  "accuracy_score": {
    "before_mean": 0.65,
    "after_mean": 0.88,
    "absolute_change": 0.23,
    "percent_change": 35.38
  }
}
```

**√ù nghƒ©a:**
- Accuracy tƒÉng t·ª´ 65% ‚Üí 88%
- Absolute change: +0.23 (tƒÉng 23 ƒëi·ªÉm %)
- Percent change: +35.38% (tƒÉng 35.38% so v·ªõi baseline)

---

## API Workflow chi ti·∫øt

```
STEP 1: Load HuggingFace dataset
  Dataset columns: [system_prompt, input, output]
  ‚Üì

STEP 2: Extract initial_prompt t·ª´ dataset
  initial_prompt = dataset[0]["system_prompt"]
  ‚Üì

STEP 3: Create optimizer
  ‚Üì

STEP 4: Run evaluators on EXISTING outputs
  ƒê√°nh gi√° outputs ƒë√£ c√≥ trong dataset
  ‚Üí Generate feedback columns (quality, explanation)
  ‚Üì

STEP 5: Optimize prompt
  D·ª±a v√†o feedback ‚Üí t·∫°o optimized_prompt
  ‚Üì

STEP 6: Calculate metrics_before ‚Üê BASELINE
  metrics_before = quality distribution c·ªßa outputs c≈©
  ‚Üì

STEP 7: Re-generate outputs v·ªõi OPTIMIZED prompt
  For each input:
    - D√πng optimized_prompt + input
    - Call LLM ‚Üí new_output
  ‚Üì

STEP 8: Re-run evaluators on NEW outputs
  ƒê√°nh gi√° l·∫°i new_outputs
  ‚Üí Generate new feedback
  ‚Üì

STEP 9: Calculate metrics_after ‚Üê RESULTS
  metrics_after = quality distribution c·ªßa outputs m·ªõi
  ‚Üì

STEP 10: Calculate improvement
  Compare metrics_before vs metrics_after
  ‚Üì

STEP 11: Return response v·ªõi ƒë·∫ßy ƒë·ªß metrics
```

---

## Real Example Output

```json
{
  "success": true,
  "initial_prompt": "B·∫°n l√† chatbot b√°n s·ªØa Abbott. Tr·∫£ l·ªùi: {customer_question}",
  "optimized_prompt": "B·∫°n l√† chatbot b√°n s·ªØa Abbott chuy√™n nghi·ªáp, th√¢n thi·ªán v√† t·∫≠n t√¢m. Tr·∫£ l·ªùi r√µ r√†ng...",

  "dataset_info": {
    "name": "user/abbott-chatbot",
    "num_samples": 10,
    "columns": ["customer_question", "chatbot_answer", "quality", "explanation"]
  },

  "usage_summary": {
    "total_cost": 0.0012,
    "total_tokens": 5200,
    "budget_usage_percentage": 0.024
  },

  "metrics_before": {
    "quality": {
      "distribution": {"poor": 5, "good": 5}
    }
  },

  "metrics_after": {
    "quality": {
      "distribution": {"poor": 1, "good": 9}
    }
  },

  "improvement": {
    "quality": {
      "before_distribution": {"poor": 5, "good": 5},
      "after_distribution": {"poor": 1, "good": 9},
      "positive_count_before": 5,
      "positive_count_after": 9,
      "improvement": 4,
      "before_positive_pct": 50.0,
      "after_positive_pct": 90.0
    }
  }
}
```

---

## Key Metrics to Watch

### 1. **Improvement Number**
```
improvement.quality.improvement = +4
```
‚Üí TƒÉng 4 c√¢u tr·∫£ l·ªùi t·ªët

### 2. **Percentage Improvement**
```
before: 50% ‚Üí after: 90% = +40%
```
‚Üí C·∫£i thi·ªán 40 ƒëi·ªÉm ph·∫ßn trƒÉm

### 3. **Total Cost**
```
usage_summary.total_cost = $0.0012
```
‚Üí Chi ph√≠ cho to√†n b·ªô qu√° tr√¨nh (optimize + re-generate + re-evaluate)

### 4. **Success Rate**
```
after_positive_pct = 90%
```
‚Üí 90% responses ƒë·∫°t ch·∫•t l∆∞·ª£ng t·ªët

---

## How to Use in Code

```python
response = requests.post("http://localhost:8435/optimize/huggingface", json=payload)
result = response.json()

# Get improvement
improvement = result["improvement"]["quality"]["improvement"]
print(f"Improved by {improvement} samples")

# Get percentage
before_pct = result["improvement"]["quality"]["before_positive_pct"]
after_pct = result["improvement"]["quality"]["after_positive_pct"]
print(f"Quality: {before_pct}% ‚Üí {after_pct}% (+{after_pct - before_pct}%)")

# Check if worth it
if after_pct >= 80:
    print("‚úÖ Optimized prompt is good enough for production!")
else:
    print("‚ö†Ô∏è May need more optimization")
```
